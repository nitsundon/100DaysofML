{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/nitsundon/100DaysofML/blob/main/Day01/LSTMrev02.ipynb",
      "authorship_tag": "ABX9TyN+r/ftnWAWVDSKtLKFmICo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitsundon/100DaysofML/blob/main/Day01/LSTMrev02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4YCpIuZ-Gva"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.express as px\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_pickle(\"/content/drive/MyDrive/Libraries/pickle/preprocessed_demand_df.pkl\")\n",
        "df['datetime']=pd.to_datetime(df['datetime'])\n"
      ],
      "metadata": {
        "id": "n9LrlmUkGnJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_datetime_features(df):\n",
        "\n",
        "\n",
        "  df['block'] = 1+df['datetime'].dt.hour * 4 + df['datetime'].dt.minute // 15\n",
        "  df['month'] = df['datetime'].dt.month\n",
        "  df['day'] = df['datetime'].dt.day\n",
        "  df['day_of_week'] = df['datetime'].dt.dayofweek\n",
        "  df['year'] = df['datetime'].dt.year\n",
        "\n",
        "  return df.copy();"
      ],
      "metadata": {
        "id": "pASHzxdDG0c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_cyclic_features(df, col, max_val,drop_original=True):\n",
        "    df[f'{col}_sin'] = np.sin(2 * np.pi * df[col]/max_val)\n",
        "    df[f'{col}_cos'] = np.cos(2 * np.pi * df[col]/max_val)\n",
        "    if(drop_original):\n",
        "      df.drop(col,axis=1,inplace=True)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "GCpys7qIH5Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_cyclic_features(df, col, max_val):\n",
        "    # Calculate the angle (theta) back from sin and cos\n",
        "    theta = np.arctan2(df[f'{col}_sin'], df[f'{col}_cos'])\n",
        "\n",
        "    # Normalize theta to be in [0, 2*pi]\n",
        "    theta = (theta + 2 * np.pi) % (2 * np.pi)\n",
        "\n",
        "    # Recover the original value\n",
        "    df[col] = (theta * max_val) / (2 * np.pi)\n",
        "    df[col]=df[col].astype(int)\n",
        "    # Optionally, you can drop sin and cos columns if you want\n",
        "    df.drop([f'{col}_sin', f'{col}_cos'], axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "hemaHSIQNO_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lags(df,lag_steps):\n",
        "  for i in range(1,lag_steps+1):\n",
        "    df[f'demand_lag_{i}']=df['demand'].shift(i)\n",
        "  return df"
      ],
      "metadata": {
        "id": "m1yTWmSHJMGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_feature_and_target(df):\n",
        "  features = df.drop('demand', axis=1)\n",
        "  target = df['demand']\n",
        "  return features,target"
      ],
      "metadata": {
        "id": "R_mK5aUvOf8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createXY(dataset,n_past):\n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    for i in range(n_past, len(dataset)):\n",
        "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
        "            dataY.append(dataset[i,0])\n",
        "    return np.array(dataX),np.array(dataY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vBMG7pAPtD3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=create_datetime_features(df)\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "2Ovf7oNH22xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_scaled_features_df(df, scaler):\n",
        "    df1 = df.copy()\n",
        "\n",
        "    # Inverse cyclic features\n",
        "    df1 = inverse_cyclic_features(df1, 'month', 12)\n",
        "    df1 = inverse_cyclic_features(df1, 'day_of_week', 7)\n",
        "    df1 = inverse_cyclic_features(df1, 'block', 96)\n",
        "    df1 = inverse_cyclic_features(df1, 'day', 31)\n",
        "\n",
        "    # Inverse scale selected columns\n",
        "    cols_to_inverse = ['demand', 'year']\n",
        "    s = scaler.inverse_transform(df1[cols_to_inverse])\n",
        "\n",
        "    # Convert back to DataFrame to maintain structure\n",
        "    s_df = pd.DataFrame(s, columns=cols_to_inverse, index=df1.index)\n",
        "\n",
        "    # Update df1 with inverse transformed values\n",
        "    df1[cols_to_inverse] = s_df\n",
        "\n",
        "    return df1, scaler"
      ],
      "metadata": {
        "id": "7zAP4E4l3M1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VrvTDvmWS22m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_scaled_features_df(df,scaler):\n",
        "  df1=df.copy()\n",
        "  df1=add_cyclic_features(df1, 'month', 12, drop_original=True)\n",
        "  df1=add_cyclic_features(df1,'day_of_week', 7, drop_original=True)\n",
        "  df1=add_cyclic_features(df1,'block', 96, drop_original=True)\n",
        "  df1=add_cyclic_features(df1,'day',31, drop_original=True)\n",
        "\n",
        "  s= scaler.fit_transform(df1[['demand','year']])\n",
        "  df1['demand']=s[:,0]\n",
        "  df1['year']=s[:,1]\n",
        "  return df1,scaler"
      ],
      "metadata": {
        "id": "-tsAJjTBSEcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_multi_output(data, seq_length, pred_length):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(seq_length, len(data) - pred_length):\n",
        "        X.append(data[i-seq_length:i, :-1])  # input features\n",
        "        y.append(data[i:i+pred_length, -1])  # 192 future targets\n",
        "    return np.array(X), np.array(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "h9J0RF-WMJHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar=MinMaxScaler()\n",
        "df1,scalar=create_scaled_features_df(df1,scalar)\n",
        "df1,type(df1)"
      ],
      "metadata": {
        "id": "rrIKXGIdTKc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=inverse_scaled_features_df(df1,scalar)\n",
        "type(df1)"
      ],
      "metadata": {
        "id": "S3rxa3D6TUFD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}