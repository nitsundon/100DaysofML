{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/nitsundon/100DaysofML/blob/main/Day01/LSTMrev02.ipynb",
      "authorship_tag": "ABX9TyNTS+BXsU1mmctTWo3cZlAg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitsundon/100DaysofML/blob/main/Day01/LSTMrev02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W4YCpIuZ-Gva"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.express as px\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_pickle(\"/content/drive/MyDrive/Libraries/pickle/preprocessed_demand_df.pkl\")\n",
        "df['datetime']=pd.to_datetime(df['datetime'])\n"
      ],
      "metadata": {
        "id": "n9LrlmUkGnJA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_datetime_features(df):\n",
        "\n",
        "\n",
        "  df['block'] = 1+df['datetime'].dt.hour * 4 + df['datetime'].dt.minute // 15\n",
        "  df['month'] = df['datetime'].dt.month\n",
        "  df['day'] = df['datetime'].dt.day\n",
        "  df['day_of_week'] = df['datetime'].dt.dayofweek\n",
        "  df['year'] = df['datetime'].dt.year\n",
        "\n",
        "  return df.copy();"
      ],
      "metadata": {
        "id": "pASHzxdDG0c1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_cyclic_features(df, col, max_val,drop_original=True):\n",
        "    df[f'{col}_sin'] = np.sin(2 * np.pi * df[col]/max_val)\n",
        "    df[f'{col}_cos'] = np.cos(2 * np.pi * df[col]/max_val)\n",
        "    if(drop_original):\n",
        "      df.drop(col,axis=1,inplace=True)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "GCpys7qIH5Iv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_cyclic_features(df, col, max_val):\n",
        "    # Calculate the angle (theta) back from sin and cos\n",
        "    theta = np.arctan2(df[f'{col}_sin'], df[f'{col}_cos'])\n",
        "\n",
        "    # Normalize theta to be in [0, 2*pi]\n",
        "    theta = (theta + 2 * np.pi) % (2 * np.pi)\n",
        "\n",
        "    # Recover the original value\n",
        "    df[col] = (theta * max_val) / (2 * np.pi)\n",
        "    df[col]=df[col].astype(int)\n",
        "    # Optionally, you can drop sin and cos columns if you want\n",
        "    df.drop([f'{col}_sin', f'{col}_cos'], axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "hemaHSIQNO_6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lags(df,lag_steps):\n",
        "  for i in range(1,lag_steps+1):\n",
        "    df[f'demand_lag_{i}']=df['demand'].shift(i)\n",
        "  return df"
      ],
      "metadata": {
        "id": "m1yTWmSHJMGn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_feature_and_target(df):\n",
        "  features = df.drop('demand', axis=1)\n",
        "  target = df['demand']\n",
        "  return features,target"
      ],
      "metadata": {
        "id": "R_mK5aUvOf8o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createXY(dataset,n_past):\n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    for i in range(n_past, len(dataset)):\n",
        "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
        "            dataY.append(dataset[i,0])\n",
        "    return np.array(dataX),np.array(dataY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vBMG7pAPtD3u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Ovf7oNH22xA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_scaled_features_df(df, scaler):\n",
        "    df1 = df.copy()\n",
        "\n",
        "    # Inverse cyclic features\n",
        "    df1 = inverse_cyclic_features(df1, 'month', 12)\n",
        "    df1 = inverse_cyclic_features(df1, 'day_of_week', 7)\n",
        "    df1 = inverse_cyclic_features(df1, 'block', 96)\n",
        "    df1 = inverse_cyclic_features(df1, 'day', 31)\n",
        "\n",
        "    # Inverse scale selected columns\n",
        "    cols_to_inverse = ['demand', 'year']\n",
        "    s = scaler.inverse_transform(df1[cols_to_inverse])\n",
        "\n",
        "    # Convert back to DataFrame to maintain structure\n",
        "    s_df = pd.DataFrame(s, columns=cols_to_inverse, index=df1.index)\n",
        "\n",
        "    # Update df1 with inverse transformed values\n",
        "\n",
        "    return s_df, scaler"
      ],
      "metadata": {
        "id": "7zAP4E4l3M1Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VrvTDvmWS22m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_scaled_features_df(df,scaler):\n",
        "  df1=df.copy()\n",
        "  df1=add_cyclic_features(df1, 'month', 12, drop_original=True)\n",
        "  df1=add_cyclic_features(df1,'day_of_week', 7, drop_original=True)\n",
        "  df1=add_cyclic_features(df1,'block', 96, drop_original=True)\n",
        "  df1=add_cyclic_features(df1,'day',31, drop_original=True)\n",
        "\n",
        "  s= scaler.fit_transform(df1[['demand','year']])\n",
        "  df1['demand']=s[:,0]\n",
        "  df1['year']=s[:,1]\n",
        "  return df1,scaler"
      ],
      "metadata": {
        "id": "-tsAJjTBSEcj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_multi_output(data, seq_length, pred_length):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(seq_length, len(data) - pred_length):\n",
        "        X.append(data[i-seq_length:i, :-1])  # input features\n",
        "        y.append(data[i:i+pred_length, -1])  # 192 future targets\n",
        "    return np.array(X), np.array(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "h9J0RF-WMJHs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=create_datetime_features(df)\n",
        "df1.columns\n",
        "scalar=MinMaxScaler()\n",
        "df1,scalar=create_scaled_features_df(df1,scalar)\n",
        "df1,type(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrIKXGIdTKc1",
        "outputId": "ae81566c-3306-4ea9-87d4-66c95a6593de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                  datetime    demand  year  month_sin  month_cos  \\\n",
              " 0      2022-01-01 00:00:00  0.326487   0.0   0.500000   0.866025   \n",
              " 1      2022-01-01 00:15:00  0.325481   0.0   0.500000   0.866025   \n",
              " 2      2022-01-01 00:30:00  0.320685   0.0   0.500000   0.866025   \n",
              " 3      2022-01-01 00:45:00  0.327153   0.0   0.500000   0.866025   \n",
              " 4      2022-01-01 01:00:00  0.328219   0.0   0.500000   0.866025   \n",
              " ...                    ...       ...   ...        ...        ...   \n",
              " 115153 2025-04-14 12:00:00  0.849394   1.0   0.866025  -0.500000   \n",
              " 115154 2025-04-14 12:15:00  0.843943   1.0   0.866025  -0.500000   \n",
              " 115155 2025-04-14 12:30:00  0.838462   1.0   0.866025  -0.500000   \n",
              " 115156 2025-04-14 12:45:00  0.842602   1.0   0.866025  -0.500000   \n",
              " 115157 2025-04-14 13:00:00  0.837958   1.0   0.866025  -0.500000   \n",
              " \n",
              "         day_of_week_sin  day_of_week_cos  block_sin  block_cos   day_sin  \\\n",
              " 0             -0.974928        -0.222521   0.065403   0.997859  0.201299   \n",
              " 1             -0.974928        -0.222521   0.130526   0.991445  0.201299   \n",
              " 2             -0.974928        -0.222521   0.195090   0.980785  0.201299   \n",
              " 3             -0.974928        -0.222521   0.258819   0.965926  0.201299   \n",
              " 4             -0.974928        -0.222521   0.321439   0.946930  0.201299   \n",
              " ...                 ...              ...        ...        ...       ...   \n",
              " 115153         0.000000         1.000000  -0.065403  -0.997859  0.299363   \n",
              " 115154         0.000000         1.000000  -0.130526  -0.991445  0.299363   \n",
              " 115155         0.000000         1.000000  -0.195090  -0.980785  0.299363   \n",
              " 115156         0.000000         1.000000  -0.258819  -0.965926  0.299363   \n",
              " 115157         0.000000         1.000000  -0.321439  -0.946930  0.299363   \n",
              " \n",
              "          day_cos  \n",
              " 0       0.979530  \n",
              " 1       0.979530  \n",
              " 2       0.979530  \n",
              " 3       0.979530  \n",
              " 4       0.979530  \n",
              " ...          ...  \n",
              " 115153 -0.954139  \n",
              " 115154 -0.954139  \n",
              " 115155 -0.954139  \n",
              " 115156 -0.954139  \n",
              " 115157 -0.954139  \n",
              " \n",
              " [114581 rows x 11 columns],\n",
              " pandas.core.frame.DataFrame)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1=inverse_scaled_features_df(df1,scalar)\n",
        "type(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3rxa3D6TUFD",
        "outputId": "64fb9284-dd3b-4b07-f363-4f462fffffe7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}